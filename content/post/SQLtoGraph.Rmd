---
title: From SQL to Plot in R
author: ''
date: '2017-05-16'
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, cache = TRUE, message = FALSE, warning = FALSE)
```

This is a very short post. I just wanted to take some time to appreciate the work done by the people behind `dplyr`. In particularly, how easy it is to connect to an SQL database, query your data, aggregate them, and end up with informative plots without having to switch between different technologies.


## From SQL to Plot
For this post i will use a local SQLite dataset, namely the flights data set that records on-time data for all flights that departed from NYC in 2013.

Say i wanted to plot the average delay per flight for each carrier. That would be as easy as: 

```{r plot1}
library(dplyr)
library(nycflights13)
library(ggplot2)
library(corrplot)

flights_sqlite <- tbl(nycflights13_sqlite(), "flights")

# Get total flights by carrier
NFlights <- flights_sqlite %>% group_by(carrier) %>%
        summarise(Nflights = n())

# Get Total Delay per Carrier
TotalDelay <- flights_sqlite %>% group_by(carrier) %>%
        mutate(Delay = arr_delay + dep_delay) %>%
        summarise(TotalDelay = sum(Delay))

# Calculate the Average Flight Delay and Graph it
NFlights %>% left_join(TotalDelay) %>%
        mutate(AverageDelay = TotalDelay / Nflights) %>%
        collect() %>%
        ggplot(.,aes(x = carrier, y = AverageDelay, fill = carrier)) +
        geom_bar(stat = 'identity')

```

Notice that while i connect to an SQLite database, i do not need to use SQL syntax since `dplyr` does the translation for me. One more thing that is important to know is that the intermediate results (i.e., NFlight and TotalDelay) where not pulled down from the database, rather, they were evaluated in a "lazy" manner. It was only when i used the verb "collect()" before the plot that the data where pulled down into my RAM.

How does this magic work? `dplyr` combines intermediate queries and delays the evaluation of the code until the "final" query, where "final" means the one you collect on. So the three intermediate tables created below (NFlights, TotalDelay, and Final.Table) will run as one combined SQL query and the results will only pulled down when i explicitly ask for it (i.e., use the `collect()` function)
```{r translate, message = TRUE}

NFlights <- flights_sqlite %>% group_by(carrier) %>%
        summarise(Nflights = n())

TotalDelay <- flights_sqlite %>% group_by(carrier) %>%
        mutate(Delay = arr_delay + dep_delay) %>%
        summarise(TotalDelay = sum(Delay))

Final.Table <- NFlights %>% left_join(TotalDelay) %>%
        mutate(AverageDelay = TotalDelay / Nflights) 

show_query(Final.Table)

```


## Combining tables and ploting/analysing.

Now say i wanted to join the "flights" table with the "weather" table to see if weather conditions affect average delay times. There are many ways to do that but i like taking some intermediate steps. They are memory inexpensive (lazy evaluation) and are easier to inspect for errors, at least when compared to huge one-liners.

```{r plot2}

flights_sqlite <- tbl(nycflights13_sqlite(), "flights")
weather_sqlite <- tbl(nycflights13_sqlite(), "weather")

# Flights per month, day, and hour
NFlights2 <- flights_sqlite %>% group_by(month, day, hour) %>% 
        summarise(Nflights = n())

# Delay per month, day, and hour
Delays <- flights_sqlite %>% group_by(month, day, hour) %>% 
        mutate(Delay = arr_delay + dep_delay) %>%
        summarise(TotalDelay = sum(Delay))
# Average Delay per hour
AverageDelay <- NFlights2 %>% left_join(Delays) %>%
        mutate(AverageDelay = TotalDelay / Nflights)

# Join with weather data and plot correlations
AverageDelay %>% left_join(weather_sqlite) %>% ungroup() %>% 
        select(AverageDelay, temp:visib) %>% collect %>%
        cor(., use = 'complete.obs') %>% corrplot

# Scatterplot with Smooth excluding one outlier for the wind_speed variable
AverageDelay %>% left_join(weather_sqlite) %>%
        filter(wind_speed < 1000) %>% ungroup() %>%
        select(AverageDelay, wind_speed) %>% collect %>%
        ggplot(.,aes(x = wind_speed, y = AverageDelay)) +
        geom_point() + geom_smooth()



```


So there seems to be  little relationship between delay times and local weather. This does make some sense, but it's not the point of the post. The point of the post is how easy `dplyr` makes the use of SQL databases for basic querying and analysis.

It kind of makes it feel like this:

![Just another Day Plotting](/img/aG9Z0b5_700b.jpg)